{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 12123.323630183251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/phik/data_quality.py:59: UserWarning: The number of unique values of variable date is large: 1035. Are you sure this is not an interval variable? Analysis for pairs of variables including date can be slow.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date       day       oc3       al4      pet2       can  \\\n",
      "date               1.0  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
      "day                1.0  1.000000  0.000000  0.000000  0.269114  0.273931   \n",
      "oc3                1.0  0.000000  1.000000  0.089138  0.111741  0.495239   \n",
      "al4                1.0  0.000000  0.089138  1.000000  0.092701  0.100432   \n",
      "pet2               1.0  0.269114  0.111741  0.092701  1.000000  0.216725   \n",
      "can                1.0  0.273931  0.495239  0.100432  0.216725  1.000000   \n",
      "gbl                1.0  0.275802  0.027664  0.046758  0.306762  0.113006   \n",
      "sachet             1.0  0.377470  0.170276  0.175343  0.204076  0.200066   \n",
      "enmix              1.0  0.645439  0.000000  0.148316  0.305503  0.252534   \n",
      "date_type          1.0  0.761246  0.243230  0.142893  0.329724  0.344650   \n",
      "status_process     1.0  0.223569  0.303069  0.413792  0.200920  0.204542   \n",
      "electric_consume   1.0  0.347886  0.000000  0.598071  0.935525  0.891306   \n",
      "\n",
      "                       gbl    sachet     enmix  date_type  status_process  \\\n",
      "date              1.000000  1.000000  1.000000   1.000000        1.000000   \n",
      "day               0.275802  0.377470  0.645439   0.761246        0.223569   \n",
      "oc3               0.027664  0.170276  0.000000   0.243230        0.303069   \n",
      "al4               0.046758  0.175343  0.148316   0.142893        0.413792   \n",
      "pet2              0.306762  0.204076  0.305503   0.329724        0.200920   \n",
      "can               0.113006  0.200066  0.252534   0.344650        0.204542   \n",
      "gbl               1.000000  0.311503  0.393608   0.468840        0.195812   \n",
      "sachet            0.311503  1.000000  0.310434   0.341892        0.217851   \n",
      "enmix             0.393608  0.310434  1.000000   0.656284        0.429757   \n",
      "date_type         0.468840  0.341892  0.656284   1.000000        0.355923   \n",
      "status_process    0.195812  0.217851  0.429757   0.355923        1.000000   \n",
      "electric_consume  0.832440  0.750913  0.000000   0.870194        0.873860   \n",
      "\n",
      "                  electric_consume  \n",
      "date                      1.000000  \n",
      "day                       0.347886  \n",
      "oc3                       0.000000  \n",
      "al4                       0.598071  \n",
      "pet2                      0.935525  \n",
      "can                       0.891306  \n",
      "gbl                       0.832440  \n",
      "sachet                    0.750913  \n",
      "enmix                     0.000000  \n",
      "date_type                 0.870194  \n",
      "status_process            0.873860  \n",
      "electric_consume          1.000000  \n",
      "Data Head:\n",
      "       date        day     oc3      al4    pet2  can  gbl  sachet   enmix  \\\n",
      "0  1/1/2022   Saturday       0        0       0    0    0       0       0   \n",
      "1  1/2/2022     Sunday  441240        0       0    0    0       0       0   \n",
      "2  1/3/2022     Monday  204816  1289657  645326    0    0       0  179835   \n",
      "3  1/4/2022    Tuesday       0  1305874  968366    0    0       0  179835   \n",
      "4  1/5/2022  Wednesday  903072  1207543  969703    0    0       0  209808   \n",
      "\n",
      "  date_type  status_process  electric_consume  \n",
      "0   weekend               0             50752  \n",
      "1   weekend               1             56624  \n",
      "2   workday               1             81504  \n",
      "3   workday               1             93808  \n",
      "4   workday               1            114544  \n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1035 entries, 0 to 1034\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   date              1035 non-null   object\n",
      " 1   day               1035 non-null   object\n",
      " 2   oc3               1035 non-null   int64 \n",
      " 3   al4               1035 non-null   int64 \n",
      " 4   pet2              1035 non-null   int64 \n",
      " 5   can               1035 non-null   int64 \n",
      " 6   gbl               1035 non-null   int64 \n",
      " 7   sachet            1035 non-null   int64 \n",
      " 8   enmix             1035 non-null   int64 \n",
      " 9   date_type         1035 non-null   object\n",
      " 10  status_process    1035 non-null   int64 \n",
      " 11  electric_consume  1035 non-null   int64 \n",
      "dtypes: int64(9), object(3)\n",
      "memory usage: 97.2+ KB\n",
      "None\n",
      "\n",
      "Data Description:\n",
      "                oc3           al4          pet2           can            gbl  \\\n",
      "count  1.035000e+03  1.035000e+03  1.035000e+03  1.035000e+03    1035.000000   \n",
      "mean   4.013708e+05  5.670771e+05  2.048947e+05  1.165092e+05   13135.987440   \n",
      "std    4.152560e+05  5.767084e+05  3.646258e+05  2.213099e+05   25563.797793   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00       0.000000   \n",
      "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00       0.000000   \n",
      "50%    2.582160e+05  4.292910e+05  0.000000e+00  0.000000e+00       0.000000   \n",
      "75%    8.852280e+05  1.211658e+06  3.501945e+05  1.869345e+05       0.000000   \n",
      "max    1.538784e+06  1.427280e+06  1.092343e+06  1.243214e+06  127600.000000   \n",
      "\n",
      "             sachet          enmix  status_process  electric_consume  \n",
      "count   1035.000000    1035.000000     1035.000000       1035.000000  \n",
      "mean   13201.822222   96492.814493        0.917874      86949.657971  \n",
      "std    22018.379025   86961.496655        0.274689      23855.289115  \n",
      "min        0.000000       0.000000        0.000000      13760.000000  \n",
      "25%        0.000000       0.000000        1.000000      72688.000000  \n",
      "50%        0.000000  133031.000000        1.000000      87280.000000  \n",
      "75%    22552.000000  177375.000000        1.000000     102752.000000  \n",
      "max    63143.000000  236500.000000        1.000000     208240.000000  \n",
      "\n",
      "Missing Values:\n",
      "date                0\n",
      "day                 0\n",
      "oc3                 0\n",
      "al4                 0\n",
      "pet2                0\n",
      "can                 0\n",
      "gbl                 0\n",
      "sachet              0\n",
      "enmix               0\n",
      "date_type           0\n",
      "status_process      0\n",
      "electric_consume    0\n",
      "dtype: int64\n",
      "\n",
      "Unique Values in Categorical Features:\n",
      "date_type: 3 unique values\n",
      "status_process: 2 unique values\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "import phik\n",
    "from phik import resources, report\n",
    "\n",
    "# Import necessary libraries\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('../data/electric-consumption (2).csv')\n",
    "\n",
    "# Define features and target variable\n",
    "features = ['oc3', 'al4', 'pet2', 'can', 'gbl', 'sachet', 'enmix', 'date_type', 'status_process']\n",
    "target = 'electric_consume'\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline for numerical and categorical features\n",
    "numeric_features = ['oc3', 'al4', 'pet2', 'can', 'gbl', 'sachet', 'enmix']\n",
    "categorical_features = ['date_type', 'status_process']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "  transformers=[\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(), categorical_features)\n",
    "  ])\n",
    "\n",
    "# Create a pipeline with preprocessing and model\n",
    "model = Pipeline(steps=[\n",
    "  ('preprocessor', preprocessor),\n",
    "  ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'electric_consumption_model.pkl')\n",
    "# Perform correlation analysis using phik\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "phik_matrix = data.phik_matrix(interval_cols=numeric_features)\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(phik_matrix)\n",
    "\n",
    "# Save the correlation matrix to a CSV file\n",
    "phik_matrix.to_csv('phik_correlation_matrix.csv')\n",
    "# Data exploration\n",
    "print(\"Data Head:\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"\\nData Info:\")\n",
    "print(data.info())\n",
    "\n",
    "print(\"\\nData Description:\")\n",
    "print(data.describe())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "print(\"\\nUnique Values in Categorical Features:\")\n",
    "for col in categorical_features:\n",
    "  print(f\"{col}: {data[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 87051.04        97803.2         94893.92       105765.6\n",
      "  73635.52        71108.96        89912.48        85754.72\n",
      "  52665.55296721  75970.72        98465.76       105210.24\n",
      "  52665.55296721  71430.24        99821.44        83024.\n",
      "  66610.24        77311.36        71411.52        71497.28\n",
      "  88987.04        95072.32        83670.24       103077.44\n",
      "  95055.2         70855.68        47960.29243054 100294.88\n",
      " 107229.76        64411.50628571  75359.04       110749.44\n",
      "  87022.56        83743.84        87527.04        78370.24\n",
      "  78088.          98385.44        85896.48        69901.76\n",
      "  89303.36        57288.05818182  80765.6        100990.24\n",
      "  86617.76        86568.64        52665.55296721  87072.64\n",
      " 117291.2         74340.48       103316.48        91373.92\n",
      "  75830.24        91391.2         62593.76       101081.6\n",
      "  82884.48        80147.84        97589.36       103028.16\n",
      "  75549.76        68609.12        93919.68        97163.04\n",
      " 102061.12        79015.2         99729.92        74838.4\n",
      "  55679.39733333 101842.24       116781.92       114316.64\n",
      "  72440.96        47960.29243054 120082.8         74277.44\n",
      "  77021.12       118154.32        69987.52       118623.2\n",
      "  76959.68       126344.          91285.12        31187.90458934\n",
      "  95915.04        31187.90458934  89919.36       114195.36\n",
      " 103827.2         81768.16       100296.8        114532.88\n",
      "  47960.29243054  97685.92       121219.68        80739.52\n",
      "  78136.          98966.08        94422.08       120552.32\n",
      "  69933.28        78260.         120546.24       102307.68\n",
      "  52665.55296721  89185.76        66140.          99791.04\n",
      " 110469.44        72678.24        69849.76        98229.44\n",
      " 116180.32        71491.2        105511.04       104403.36\n",
      "  94713.76        63649.44       121464.16        94911.04\n",
      "  75798.24        86460.         123580.08        80471.84\n",
      "  98918.24        82629.6        105937.6        110685.6\n",
      "  67999.36       110399.36        71877.12        77029.12\n",
      "  81537.44        86879.2         68685.12        90972.64\n",
      "  91429.76        67821.95555556 109603.04        74470.56\n",
      "  84290.24        86204.         111692.96        74147.04\n",
      " 104598.08        90657.12        63661.69612698  52665.55296721\n",
      "  86467.2         65008.          83776.32        88055.84\n",
      " 118807.84        82146.24       112358.4        106216.\n",
      "  52665.55296721  52665.55296721 113504.8        100140.\n",
      "  88874.08        90812.         104879.36       117554.32\n",
      "  31187.90458934 115081.92        96693.68       111651.36\n",
      "  66490.88        94715.68        95161.92        31187.90458934\n",
      "  52665.55296721  91002.56        31187.90458934  74820.16\n",
      "  75863.52        92382.4         80842.56        52665.55296721\n",
      " 129822.88        78260.8         74147.04        80337.12\n",
      " 104086.24        99182.72        90400.          56776.47873016\n",
      "  94464.16        71918.72        88355.2         75407.36\n",
      " 107131.2        107890.08        85569.28       104505.76\n",
      "  74876.8        101685.12        96926.08        73076.83555556\n",
      "  88987.84        90274.24        94809.28        68622.08\n",
      "  85685.44       102634.4        101797.6       ]\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = joblib.load('electric_consumption_model.pkl')\n",
    "\n",
    "# Make predictions on the test set\n",
    "new_predictions = loaded_model.predict(X_test)\n",
    "\n",
    "# Display the predictions\n",
    "print(new_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57288.05818182 65476.09777778]\n"
     ]
    }
   ],
   "source": [
    "# Create dummy data\n",
    "sample_data_input = pd.DataFrame({\n",
    "  'oc3': [0.5, 0.7],\n",
    "  'al4': [0.3, 0.6],\n",
    "  'pet2': [0.2, 0.8],\n",
    "  'can': [0.1, 0.4],\n",
    "  'gbl': [0.5, 0.9],\n",
    "  'sachet': [0.3, 0.7],\n",
    "  'enmix': [0.4, 0.6],\n",
    "  'date_type': ['workday', 'weekend'],\n",
    "  'status_process': [1, 1]\n",
    "})\n",
    "\n",
    "# Make predictions on the dummy data\n",
    "dummy_predictions = loaded_model.predict(sample_data_input)\n",
    "\n",
    "# Display the predictions\n",
    "print(dummy_predictions)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
